{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f6ccbe",
   "metadata": {},
   "source": [
    "# Popularity Prediction for UCSD Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from popularity import * # TODO: fix imports\n",
    "# TODO: I think would be smart to use the runner code from popularity.py within this file so we can work on migrating that stuff here\n",
    "from baseline import * # TODO: fix imports\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168dbb9a",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(x, min_val, max_val):\n",
    "    return max(min_val, min(x, max_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9e091",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f201324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03e500b4",
   "metadata": {},
   "source": [
    "## baseline runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e82350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "baseline rating prediction (from baselines.py)\n",
    "\"\"\"\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "\n",
    "for user, book, rating in ratingsTrain:\n",
    "    allRatings.append(rating)\n",
    "    userRatings[user].append(rating)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "\n",
    "# compute mse on validation set\n",
    "mse = 0\n",
    "for user, book, rating in ratingsValid:\n",
    "    if user in userAverage:\n",
    "        pred = userAverage[user]\n",
    "    else:\n",
    "        pred = globalAverage\n",
    "    mse += (pred - rating) ** 2\n",
    "mse /= len(ratingsValid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fc922",
   "metadata": {},
   "source": [
    "## runner code for popularity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train and evaluate rating prediction model\n",
    "\"\"\"\n",
    "# hyperparameters\n",
    "lambdaU = 3.5\n",
    "lambdaI = 16\n",
    "validationSplit = 0.1\n",
    "finalTrainingRounds = 10\n",
    "\n",
    "# file paths\n",
    "trainPath = \"\" # TODO: fix path\n",
    "\n",
    "# load all ratings\n",
    "allRatings = []\n",
    "for user, book, rating in readCSV(trainPath):\n",
    "    allRatings.append((user, book, rating))\n",
    "\n",
    "# split into train/validation\n",
    "random.seed(42)\n",
    "random.shuffle(allRatings)\n",
    "split_idx = int(len(allRatings) * (1 - validationSplit))\n",
    "ratingsTrain = allRatings[:split_idx]\n",
    "ratingsValid = allRatings[split_idx:]\n",
    "\n",
    "# build per-user and per-item dictionaries\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "\n",
    "for user, item, rating in ratingsTrain:\n",
    "    ratingsPerUser[user].append((item, rating))\n",
    "    ratingsPerItem[item].append((user, rating))\n",
    "\n",
    "print(\n",
    "    f\"\\ntraining on {len(ratingsTrain)} ratings, validating on {len(ratingsValid)} ratings\"\n",
    ")\n",
    "print(f\"unique users: {len(ratingsPerUser)}, unique items: {len(ratingsPerItem)}\")\n",
    "\n",
    "# baseline model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BASELINE MODEL\")\n",
    "print(\"=\" * 60)\n",
    "baseline_MSE = runRatingBaselinePrediction(ratingsTrain, ratingsValid)\n",
    "print(f\"baseline validation MSE: {baseline_MSE:.4f}\")\n",
    "\n",
    "# train model with validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MY MODEL (Bias-Only Model)\")\n",
    "print(f\"lambdaU: {lambdaU}, lambdaI: {lambdaI}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "alpha, betaU, betaI, my_MSE = myRatingModel(\n",
    "    ratingsTrain,\n",
    "    ratingsValid,\n",
    "    ratingsPerUser,\n",
    "    ratingsPerItem,\n",
    "    lambdaU,\n",
    "    lambdaI,\n",
    ")\n",
    "\n",
    "print(f\"\\nfinal validation MSE: {my_MSE:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"baseline MSE: {baseline_MSE:.4f}\")\n",
    "print(f\"my MSE:       {my_MSE:.4f}\")\n",
    "improvement = baseline_MSE - my_MSE\n",
    "improvement_pct = (improvement / baseline_MSE) * 100\n",
    "print(f\"improvement:  {improvement:+.4f} ({improvement_pct:+.2f}%)\")\n",
    "\n",
    "# retrain on all data for final rounds\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"FINAL TRAINING: {finalTrainingRounds} rounds on all data\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# rebuild per-user and per-item dictionaries with all data\n",
    "ratingsPerUserAll = defaultdict(list)\n",
    "ratingsPerItemAll = defaultdict(list)\n",
    "\n",
    "for user, item, rating in allRatings:\n",
    "    ratingsPerUserAll[user].append((item, rating))\n",
    "    ratingsPerItemAll[item].append((user, rating))\n",
    "\n",
    "# continue training from the current parameters\n",
    "for i in range(finalTrainingRounds):\n",
    "    alpha = alphaUpdate(allRatings, alpha, betaU, betaI)\n",
    "    betaU = betaUUpdate(ratingsPerUserAll, alpha, betaU, betaI, lambdaU)\n",
    "    betaI = betaIUpdate(ratingsPerItemAll, alpha, betaU, betaI, lambdaI)\n",
    "\n",
    "    trainMSE, trainMSEReg = msePlusReg(\n",
    "        allRatings,\n",
    "        alpha,\n",
    "        betaU,\n",
    "        betaI,\n",
    "        lambdaU,\n",
    "        lambdaI,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Round {i + 1}: Training MSE = {trainMSE:.4f}, MSE+Reg = {trainMSEReg:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nfinal training MSE after combined data: {trainMSE:.4f}\")\n",
    "\n",
    "my_MSE, baseline_MSE\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
