{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f6ccbe",
   "metadata": {},
   "source": [
    "# Popularity Prediction for UCSD Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2301e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bias_only import biasOnlyModel, getBiasOnlyPreds\n",
    "from models.baseline import baselineMSE\n",
    "from models.latent_factor import latent_factor_model\n",
    "from models.tfidf import tfidfRidgeReg\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168dbb9a",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bb3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(x, min_val, max_val):\n",
    "    return max(min_val, min(x, max_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9e091",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f201324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 51764 ratings.\n",
      "Training: 46587, Validation: 5177\n",
      "Unique users: 4977, Unique items: 3243\n"
     ]
    }
   ],
   "source": [
    "# file path\n",
    "data_path = \"../data/CAPEs_with_features.csv\"\n",
    "\n",
    "# read CSV\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# filter relevant columns and drop NaNs in target\n",
    "# target: rcmd_class (percentage 0-100)\n",
    "tfidf_cols = [c for c in df.columns if c.startswith(\"tfidf_\")]\n",
    "df = df[['instructor', 'sub_course'] + tfidf_cols + ['rcmd_class']].dropna()\n",
    "\n",
    "# Extract department\n",
    "df['department'] = df['sub_course'].apply(lambda x: x.split()[0] if isinstance(x, str) else 'UNKNOWN')\n",
    "\n",
    "# Create item -> department mapping\n",
    "itemToDept = df.set_index('sub_course')['department'].to_dict()\n",
    "\n",
    "# Create allRatings list: (user, item, rating)\n",
    "allRatings = []\n",
    "allRatingsWithTFIDF = []\n",
    "for _, row in df.iterrows():\n",
    "    allRatings.append((row['instructor'], row['sub_course'], row['rcmd_class']))\n",
    "    allRatingsWithTFIDF.append([row[col] for col in ['instructor', 'sub_course'] + tfidf_cols + ['rcmd_class']])\n",
    "\n",
    "# Split into train/validation\n",
    "validationSplit = 0.1\n",
    "random.seed(42)\n",
    "random.shuffle(allRatings)\n",
    "split_idx = int(len(allRatings) * (1 - validationSplit))\n",
    "ratingsTrain = allRatings[:split_idx]\n",
    "ratingsValid = allRatings[split_idx:]\n",
    "ratingsTrainWithTFIDF = allRatingsWithTFIDF[:split_idx]\n",
    "ratingsValidWithTFIDF = allRatingsWithTFIDF[split_idx:]\n",
    "\n",
    "# Build per-user and per-item dictionaries\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "\n",
    "for user, item, rating in ratingsTrain:\n",
    "    ratingsPerUser[user].append((item, rating))\n",
    "    ratingsPerItem[item].append((user, rating))\n",
    "\n",
    "print(f\"Loaded {len(allRatings)} ratings.\")\n",
    "print(f\"Training: {len(ratingsTrain)}, Validation: {len(ratingsValid)}\")\n",
    "print(f\"Unique users: {len(ratingsPerUser)}, Unique items: {len(ratingsPerItem)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec9b99d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fulkerson, Matthew Todd', 'PHIL 137', 85.7)\n"
     ]
    }
   ],
   "source": [
    "print(ratingsTrain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e500b4",
   "metadata": {},
   "source": [
    "## baseline runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e82350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global average prediction: 89.4381\n",
      "baseline mse on validation set: 145.0333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "baseline rating prediction using the global average\n",
    "\"\"\"\n",
    "\n",
    "baseline_MSE, global_avg = baselineMSE(ratingsTrain, ratingsValid)\n",
    "print(f\"global average prediction: {global_avg:.4f}\")\n",
    "print(f\"baseline mse on validation set: {baseline_MSE:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fc922",
   "metadata": {},
   "source": [
    "## pipeline for popularity prediction (bias-only model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f86dad",
   "metadata": {},
   "source": [
    "### hyperparameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f62fe3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top grid-search results (lambdaU, lambdaI, MSE):\n",
      "  (3.5, 8) -> 97.6604\n",
      "  (5.0, 8) -> 97.6806\n",
      "  (3.5, 4) -> 97.7190\n",
      "  (5.0, 4) -> 97.7817\n",
      "  (3.5, 12) -> 98.0576\n",
      "\n",
      "best combination -> lambdaU: 3.5, lambdaI: 8, MSE: 97.6604\n"
     ]
    }
   ],
   "source": [
    "lambdaU_grid = [0.5, 1.0, 2.0, 3.5, 5.0]\n",
    "lambdaI_grid = [4, 8, 12, 16, 20]\n",
    "\n",
    "search_results = []\n",
    "best_result = {\"lambdaU\": None, \"lambdaI\": None, \"mse\": float(\"inf\")}\n",
    "\n",
    "for lambU in lambdaU_grid:\n",
    "    for lambI in lambdaI_grid:\n",
    "        _, _, _, mse, _ = biasOnlyModel(\n",
    "            ratingsTrain,\n",
    "            ratingsValid,\n",
    "            ratingsPerUser,\n",
    "            ratingsPerItem,\n",
    "            lambU,\n",
    "            lambI,\n",
    "            itemToDept\n",
    "        )\n",
    "        search_results.append((lambU, lambI, mse))\n",
    "        if mse < best_result[\"mse\"]:\n",
    "            best_result = {\"lambdaU\": lambU, \"lambdaI\": lambI, \"mse\": mse}\n",
    "\n",
    "search_results.sort(key=lambda x: x[2])\n",
    "\n",
    "print(\"top grid-search results (lambdaU, lambdaI, MSE):\")\n",
    "for lambU, lambI, mse in search_results[:5]:\n",
    "    print(f\"  ({lambU}, {lambI}) -> {mse:.4f}\")\n",
    "\n",
    "best_lambdaU = best_result[\"lambdaU\"]\n",
    "best_lambdaI = best_result[\"lambdaI\"]\n",
    "best_grid_mse = best_result[\"mse\"]\n",
    "\n",
    "print(\n",
    "    f\"\\nbest combination -> lambdaU: {best_lambdaU}, lambdaI: {best_lambdaI}, MSE: {best_grid_mse:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109eb638",
   "metadata": {},
   "source": [
    "### pipeline (bias-only model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77d1877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using lambdaU=3.5, lambdaI=8\n",
      "(grid-search validation mse: 97.6604)\n",
      "\n",
      "============================================================\n",
      "Bias-Only Model\n",
      "lambdaU: 3.5, lambdaI: 8\n",
      "============================================================\n",
      "Iteration 1: Training MSE = 85.2075, MSE+Reg = 479088.4673, Valid MSE = 99.6798\n",
      "Iteration 2: Training MSE = 83.5149, MSE+Reg = 456600.7283, Valid MSE = 98.1274\n",
      "Iteration 3: Training MSE = 83.1693, MSE+Reg = 457393.2662, Valid MSE = 97.8498\n",
      "Iteration 4: Training MSE = 83.0413, MSE+Reg = 458767.9392, Valid MSE = 97.7567\n",
      "Iteration 5: Training MSE = 82.9795, MSE+Reg = 459669.4548, Valid MSE = 97.7154\n",
      "Iteration 6: Training MSE = 82.9448, MSE+Reg = 460229.4937, Valid MSE = 97.6937\n",
      "Iteration 7: Training MSE = 82.9234, MSE+Reg = 460589.6576, Valid MSE = 97.6810\n",
      "Iteration 8: Training MSE = 82.9092, MSE+Reg = 460832.6774, Valid MSE = 97.6731\n",
      "Iteration 9: Training MSE = 82.8993, MSE+Reg = 461003.7532, Valid MSE = 97.6680\n",
      "Iteration 10: Training MSE = 82.8923, MSE+Reg = 461128.1484, Valid MSE = 97.6647\n",
      "Iteration 11: Training MSE = 82.8871, MSE+Reg = 461220.7381, Valid MSE = 97.6626\n",
      "Iteration 12: Training MSE = 82.8832, MSE+Reg = 461290.8247, Valid MSE = 97.6613\n",
      "Iteration 13: Training MSE = 82.8802, MSE+Reg = 461344.5633, Valid MSE = 97.6607\n",
      "Iteration 14: Training MSE = 82.8778, MSE+Reg = 461386.2179, Valid MSE = 97.6604\n",
      "Iteration 15: Training MSE = 82.8760, MSE+Reg = 461418.8437, Valid MSE = 97.6604\n",
      "Iteration 16: Training MSE = 82.8745, MSE+Reg = 461444.6795, Valid MSE = 97.6606\n",
      "Iteration 17: Training MSE = 82.8734, MSE+Reg = 461465.3881, Valid MSE = 97.6609\n",
      "Iteration 18: Training MSE = 82.8724, MSE+Reg = 461482.2135, Valid MSE = 97.6614\n",
      "Iteration 19: Training MSE = 82.8716, MSE+Reg = 461496.0898, Valid MSE = 97.6618\n",
      "early stopping at iteration 19\n",
      "\n",
      "final validation MSE: 97.6604\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "baseline MSE:  145.0333\n",
      "bias-only MSE: 97.6604\n",
      "improvement:  +47.3729 (+32.66%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train and evaluate rating prediction model\n",
    "\"\"\"\n",
    "\n",
    "# hyperparameters chosen via grid search (fallback to defaults if not run yet)\n",
    "lambdaU = globals().get(\"best_lambdaU\")\n",
    "lambdaI = globals().get(\"best_lambdaI\")\n",
    "\n",
    "print(f\"using lambdaU={lambdaU}, lambdaI={lambdaI}\")\n",
    "if \"best_grid_mse\" in globals():\n",
    "    print(f\"(grid-search validation mse: {best_grid_mse:.4f})\")\n",
    "\n",
    "# train model with validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Bias-Only Model\")\n",
    "print(f\"lambdaU: {lambdaU}, lambdaI: {lambdaI}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "alpha, betaU, betaI, my_MSE, globalAlpha = biasOnlyModel(\n",
    "    ratingsTrain,\n",
    "    ratingsValid,\n",
    "    ratingsPerUser,\n",
    "    ratingsPerItem,\n",
    "    lambdaU,\n",
    "    lambdaI,\n",
    "    itemToDept,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nfinal validation MSE: {my_MSE:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"baseline MSE:  {baseline_MSE:.4f}\")\n",
    "print(f\"bias-only MSE: {my_MSE:.4f}\")\n",
    "improvement = baseline_MSE - my_MSE\n",
    "improvement_pct = (improvement / baseline_MSE) * 100\n",
    "print(f\"improvement:  {improvement:+.4f} ({improvement_pct:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6af214e",
   "metadata": {},
   "source": [
    "## Latent-factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf4a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfm_model = latent_factor_model(\n",
    "    n_factors=20,\n",
    "    lr=0.01,\n",
    "    reg=0.02,\n",
    "    n_epochs=10,\n",
    "    shuffle=True,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b139a9e4",
   "metadata": {},
   "source": [
    "*warm-start, fit the model with optimized beta_u, beta_i, and alpha*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e411db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, train MSE = 86.7221\n",
      "Epoch 2/10, train MSE = 83.9317\n",
      "Epoch 3/10, train MSE = 82.7788\n",
      "Epoch 4/10, train MSE = 81.5479\n",
      "Epoch 5/10, train MSE = 81.0064\n",
      "Epoch 6/10, train MSE = 80.2306\n",
      "Epoch 7/10, train MSE = 80.0182\n",
      "Epoch 8/10, train MSE = 79.4754\n",
      "Epoch 9/10, train MSE = 79.0498\n",
      "Epoch 10/10, train MSE = 78.7988\n"
     ]
    }
   ],
   "source": [
    "lfm_model.alpha = alpha\n",
    "lfm_model.beta_I = betaI.copy()\n",
    "lfm_model.beta_U = betaU.copy()\n",
    "lfm_model.fit(ratingsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e798a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mse is 98.67607321500175\n"
     ]
    }
   ],
   "source": [
    "errors=[]\n",
    "for u,i,r in ratingsValid:\n",
    "    pred = lfm_model.predict(u,i)\n",
    "    err = r- pred\n",
    "    errors.append(err)\n",
    "\n",
    "mse = np.mean(np.square(errors))\n",
    "print(f\"the mse is {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3da78c",
   "metadata": {},
   "source": [
    "## bias/lfm + tfidf model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a5c19",
   "metadata": {},
   "source": [
    "For each bias-only and lfm-only model, we take the residuals between the training data predictions and the respective training data recommendation percentage (rating). We then train a ridge regression model to use the TF-IDF vectors to predict the respective residuals, then add the predicted residual with the bias-only/lfm-only prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90acd7c0",
   "metadata": {},
   "source": [
    "bias + tfidf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a286d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "biasOnlyPreds = getBiasOnlyPreds(\n",
    "    ratingsTrain,\n",
    "    alpha,\n",
    "    betaU,\n",
    "    betaI,\n",
    "    itemToDept,\n",
    "    globalAlpha\n",
    ")\n",
    "biasOnlyPreds = np.array(biasOnlyPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "077a1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = tfidfRidgeReg(\n",
    "    ratingsTrainWithTFIDF,\n",
    "    biasOnlyPreds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e18fb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 125.09149877754581\n"
     ]
    }
   ],
   "source": [
    "valid_mse = 0\n",
    "for row in ratingsValidWithTFIDF:\n",
    "    user = row[0]\n",
    "    item = row[1]\n",
    "    tfidf = row[2:-1]\n",
    "    rating = row[-1]\n",
    "    \n",
    "    bu = betaU.get(user, 0)\n",
    "    bi = betaI.get(item, 0)\n",
    "    dept = itemToDept.get(item, \"UNKNOWN\")\n",
    "    a = alpha.get(dept, globalAlpha)\n",
    "    \n",
    "    biasOnlyPred = a + bu + bi\n",
    "    tfidfPred = tfidf_model.predict([tfidf])[0]\n",
    "    pred = biasOnlyPred + tfidfPred\n",
    "    valid_mse += (pred - rating) ** 2\n",
    "valid_mse /= len(ratingsValidWithTFIDF)\n",
    "print(f\"Validation MSE: {valid_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2973019",
   "metadata": {},
   "source": [
    "lfm + tfidf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3610830",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfmOnlyPreds = []\n",
    "for u,i,_ in ratingsTrain:\n",
    "    pred = lfm_model.predict(u,i)\n",
    "    lfmOnlyPreds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d37e0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = tfidfRidgeReg(\n",
    "    ratingsTrainWithTFIDF,\n",
    "    lfmOnlyPreds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dfd9600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 122.05530615765049\n"
     ]
    }
   ],
   "source": [
    "valid_mse = 0\n",
    "for row in ratingsValidWithTFIDF:\n",
    "    user = row[0]\n",
    "    item = row[1]\n",
    "    tfidf = row[2:-1]\n",
    "    rating = row[-1]\n",
    "    \n",
    "    lfmOnlyPred = lfm_model.predict(user, item)\n",
    "    tfidfPred = tfidf_model.predict([tfidf])[0]\n",
    "    pred = lfmOnlyPred + tfidfPred\n",
    "    valid_mse += (pred - rating) ** 2\n",
    "valid_mse /= len(ratingsValidWithTFIDF)\n",
    "print(f\"Validation MSE: {valid_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse258",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
