{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f6ccbe",
   "metadata": {},
   "source": [
    "# Popularity Prediction for UCSD Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2301e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from popularity import myRatingModel\n",
    "from baseline import global_average_mse\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168dbb9a",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bb3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(x, min_val, max_val):\n",
    "    return max(min_val, min(x, max_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9e091",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f201324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 51764 ratings.\n",
      "Training: 46587, Validation: 5177\n",
      "Unique users: 4977, Unique items: 3243\n"
     ]
    }
   ],
   "source": [
    "# file path\n",
    "data_path = \"../data/CAPEs_with_features.csv\"\n",
    "\n",
    "# read CSV\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# filter relevant columns and drop NaNs in target\n",
    "# target: rcmd_class (percentage 0-100)\n",
    "df = df[['instructor', 'sub_course', 'rcmd_class']].dropna()\n",
    "\n",
    "# Extract department\n",
    "df['department'] = df['sub_course'].apply(lambda x: x.split()[0] if isinstance(x, str) else 'UNKNOWN')\n",
    "\n",
    "# Create item -> department mapping\n",
    "itemToDept = df.set_index('sub_course')['department'].to_dict()\n",
    "\n",
    "# Create allRatings list: (user, item, rating)\n",
    "allRatings = []\n",
    "for _, row in df.iterrows():\n",
    "    allRatings.append((row['instructor'], row['sub_course'], row['rcmd_class']))\n",
    "\n",
    "# Split into train/validation\n",
    "validationSplit = 0.1\n",
    "random.seed(42)\n",
    "random.shuffle(allRatings)\n",
    "split_idx = int(len(allRatings) * (1 - validationSplit))\n",
    "ratingsTrain = allRatings[:split_idx]\n",
    "ratingsValid = allRatings[split_idx:]\n",
    "\n",
    "# Build per-user and per-item dictionaries\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "\n",
    "for user, item, rating in ratingsTrain:\n",
    "    ratingsPerUser[user].append((item, rating))\n",
    "    ratingsPerItem[item].append((user, rating))\n",
    "\n",
    "print(f\"Loaded {len(allRatings)} ratings.\")\n",
    "print(f\"Training: {len(ratingsTrain)}, Validation: {len(ratingsValid)}\")\n",
    "print(f\"Unique users: {len(ratingsPerUser)}, Unique items: {len(ratingsPerItem)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e500b4",
   "metadata": {},
   "source": [
    "## baseline runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e82350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global average prediction: 89.4381\n",
      "baseline mse on validation set: 145.0333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "baseline rating prediction using the global average\n",
    "\"\"\"\n",
    "\n",
    "baseline_MSE, global_avg = global_average_mse(ratingsTrain, ratingsValid)\n",
    "print(f\"global average prediction: {global_avg:.4f}\")\n",
    "print(f\"baseline mse on validation set: {baseline_MSE:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fc922",
   "metadata": {},
   "source": [
    "## pipeline for popularity prediction (bias-only model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f86dad",
   "metadata": {},
   "source": [
    "### hyperparameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62fe3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top grid-search results (lambdaU, lambdaI, MSE):\n",
      "  (3.5, 8) -> 97.6604\n",
      "  (5.0, 8) -> 97.6806\n",
      "  (3.5, 4) -> 97.7190\n",
      "  (5.0, 4) -> 97.7817\n",
      "  (3.5, 12) -> 98.0576\n",
      "\n",
      "best combination -> lambdaU: 3.5, lambdaI: 8, MSE: 97.6604\n"
     ]
    }
   ],
   "source": [
    "lambdaU_grid = [0.5, 1.0, 2.0, 3.5, 5.0]\n",
    "lambdaI_grid = [4, 8, 12, 16, 20]\n",
    "\n",
    "search_results = []\n",
    "best_result = {\"lambdaU\": None, \"lambdaI\": None, \"mse\": float(\"inf\")}\n",
    "\n",
    "for lambU in lambdaU_grid:\n",
    "    for lambI in lambdaI_grid:\n",
    "        _, _, _, mse, _ = myRatingModel(\n",
    "            ratingsTrain,\n",
    "            ratingsValid,\n",
    "            ratingsPerUser,\n",
    "            ratingsPerItem,\n",
    "            lambU,\n",
    "            lambI,\n",
    "            itemToDept\n",
    "        )\n",
    "        search_results.append((lambU, lambI, mse))\n",
    "        if mse < best_result[\"mse\"]:\n",
    "            best_result = {\"lambdaU\": lambU, \"lambdaI\": lambI, \"mse\": mse}\n",
    "\n",
    "search_results.sort(key=lambda x: x[2])\n",
    "\n",
    "print(\"top grid-search results (lambdaU, lambdaI, MSE):\")\n",
    "for lambU, lambI, mse in search_results[:5]:\n",
    "    print(f\"  ({lambU}, {lambI}) -> {mse:.4f}\")\n",
    "\n",
    "best_lambdaU = best_result[\"lambdaU\"]\n",
    "best_lambdaI = best_result[\"lambdaI\"]\n",
    "best_grid_mse = best_result[\"mse\"]\n",
    "\n",
    "print(\n",
    "    f\"\\nbest combination -> lambdaU: {best_lambdaU}, lambdaI: {best_lambdaI}, MSE: {best_grid_mse:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109eb638",
   "metadata": {},
   "source": [
    "### pipeline (bias-only model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77d1877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using lambdaU=3.5, lambdaI=8\n",
      "(grid-search validation mse: 97.6604)\n",
      "\n",
      "============================================================\n",
      "MY MODEL (Bias-Only Model)\n",
      "lambdaU: 3.5, lambdaI: 8\n",
      "============================================================\n",
      "Iteration 1: Training MSE = 85.2075, MSE+Reg = 479088.4673, Valid MSE = 99.6798\n",
      "Iteration 2: Training MSE = 83.5149, MSE+Reg = 456600.7283, Valid MSE = 98.1274\n",
      "Iteration 3: Training MSE = 83.1693, MSE+Reg = 457393.2662, Valid MSE = 97.8498\n",
      "Iteration 4: Training MSE = 83.0413, MSE+Reg = 458767.9392, Valid MSE = 97.7567\n",
      "Iteration 5: Training MSE = 82.9795, MSE+Reg = 459669.4548, Valid MSE = 97.7154\n",
      "Iteration 6: Training MSE = 82.9448, MSE+Reg = 460229.4937, Valid MSE = 97.6937\n",
      "Iteration 7: Training MSE = 82.9234, MSE+Reg = 460589.6576, Valid MSE = 97.6810\n",
      "Iteration 8: Training MSE = 82.9092, MSE+Reg = 460832.6774, Valid MSE = 97.6731\n",
      "Iteration 9: Training MSE = 82.8993, MSE+Reg = 461003.7532, Valid MSE = 97.6680\n",
      "Iteration 10: Training MSE = 82.8923, MSE+Reg = 461128.1484, Valid MSE = 97.6647\n",
      "Iteration 11: Training MSE = 82.8871, MSE+Reg = 461220.7381, Valid MSE = 97.6626\n",
      "Iteration 12: Training MSE = 82.8832, MSE+Reg = 461290.8247, Valid MSE = 97.6613\n",
      "Iteration 13: Training MSE = 82.8802, MSE+Reg = 461344.5633, Valid MSE = 97.6607\n",
      "Iteration 14: Training MSE = 82.8778, MSE+Reg = 461386.2179, Valid MSE = 97.6604\n",
      "Iteration 15: Training MSE = 82.8760, MSE+Reg = 461418.8437, Valid MSE = 97.6604\n",
      "Iteration 16: Training MSE = 82.8745, MSE+Reg = 461444.6795, Valid MSE = 97.6606\n",
      "Iteration 17: Training MSE = 82.8734, MSE+Reg = 461465.3881, Valid MSE = 97.6609\n",
      "Iteration 18: Training MSE = 82.8724, MSE+Reg = 461482.2135, Valid MSE = 97.6614\n",
      "Iteration 19: Training MSE = 82.8716, MSE+Reg = 461496.0898, Valid MSE = 97.6618\n",
      "early stopping at iteration 19\n",
      "\n",
      "final validation MSE: 97.6604\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "baseline MSE: 145.0333\n",
      "my MSE:       97.6604\n",
      "improvement:  +47.3729 (+32.66%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train and evaluate rating prediction model\n",
    "\"\"\"\n",
    "\n",
    "# hyperparameters chosen via grid search (fallback to defaults if not run yet)\n",
    "lambdaU = globals().get(\"best_lambdaU\")\n",
    "lambdaI = globals().get(\"best_lambdaI\")\n",
    "\n",
    "print(f\"using lambdaU={lambdaU}, lambdaI={lambdaI}\")\n",
    "if \"best_grid_mse\" in globals():\n",
    "    print(f\"(grid-search validation mse: {best_grid_mse:.4f})\")\n",
    "\n",
    "# train model with validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MY MODEL (Bias-Only Model)\")\n",
    "print(f\"lambdaU: {lambdaU}, lambdaI: {lambdaI}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "alpha, betaU, betaI, my_MSE, globalAlpha = myRatingModel(\n",
    "    ratingsTrain,\n",
    "    ratingsValid,\n",
    "    ratingsPerUser,\n",
    "    ratingsPerItem,\n",
    "    lambdaU,\n",
    "    lambdaI,\n",
    "    itemToDept,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nfinal validation MSE: {my_MSE:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"baseline MSE: {baseline_MSE:.4f}\")\n",
    "print(f\"my MSE:       {my_MSE:.4f}\")\n",
    "improvement = baseline_MSE - my_MSE\n",
    "improvement_pct = (improvement / baseline_MSE) * 100\n",
    "print(f\"improvement:  {improvement:+.4f} ({improvement_pct:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9ea96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
